{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Fake Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Instance of Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Classes for Each MySQL Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be generating 10,000 fake users whose Twitter handles are their names concatenated. We assume that every name will be unique, and thus every handle will be unique. The email addresses will be the handles @ a certain random email provider, with a bias towards @gmail.com.\n",
    "\n",
    "Each MySQL table will have its own unique class below. The __init__ method will initialize each instance of the class with each of the features of the MySQL table. We will then iterate over a list of these objects to generate a list of tuples that will then be converted into a string that will be part of the MySQL multi-line insert query for each table.\n",
    "\n",
    "Note: While experimenting with the number of possible unique hashtags, I discovered that the number of unique words generated from fake.text() did not exceed 960. This is probably a limitation of the Faker library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self):\n",
    "        # Generate a fake name for the user with Faker\n",
    "        self.full_name = fake.name()\n",
    "        \n",
    "        # Use the fake name to create user_handle, first_name, last_name attributes\n",
    "        self.user_handle = \"\".join(self.full_name.split())\n",
    "        self.first_name = self.full_name.split()[0]\n",
    "        self.last_name = self.full_name.split()[1]\n",
    "        \n",
    "        # Create email_address attribute\n",
    "        n = randint(1,5)\n",
    "        if n==1 or n==2:\n",
    "            self.email_address = self.user_handle+'@gmail.com'\n",
    "        elif n==3:\n",
    "            self.email_address = self.user_handle+'@yahoo.com'\n",
    "        else:\n",
    "            self.email_address = self.user_handle+'@hotmail.com'\n",
    "        \n",
    "        # Create phone_number attribute\n",
    "        self.phone_number = str(randint(2000000000,9999999999))\n",
    "        \n",
    "        # Create birthday attribute\n",
    "        self.birthday = str(fake.date_of_birth(minimum_age=13,maximum_age=50))\n",
    "\n",
    "class Follower:\n",
    "    def __init__(self):\n",
    "        # A user cannot follow his/herself, thus the validation while loop below. \n",
    "        # This could also be validated on the client side.\n",
    "        while True:\n",
    "            x = randint(1,10001)\n",
    "            y = randint(1,10001)\n",
    "            if x==y:\n",
    "                pass\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        self.follower_id = x\n",
    "        self.following_id = y\n",
    "\n",
    "class Tweet:\n",
    "    def __init__(self):\n",
    "        self.user_id = randint(1, 10001)\n",
    "\n",
    "        random_tweet = fake.text()\n",
    "        if len(random_tweet) > 280:\n",
    "            random_tweet = random_tweet[0,279]\n",
    "        self.tweet_text = random_tweet\n",
    "\n",
    "class BaseComment:\n",
    "    def __init__(self):\n",
    "        self.op_tweet_id = randint(1, 100001)\n",
    "        self.commenter_id = randint(1, 10001)\n",
    "        \n",
    "        random_text = fake.text()\n",
    "        if len(random_text) > 280:\n",
    "            random_text = random_text[0,279]\n",
    "        self.comment_text = random_text\n",
    "\n",
    "class SubComment:\n",
    "    def __init__(self):\n",
    "        self.parent_comment_id = randint(1, 100001)\n",
    "        self.op_tweet_id = randint(1, 100001)\n",
    "        self.commenter_id = randint(1, 10001)\n",
    "        \n",
    "        random_text = fake.text()\n",
    "        if len(random_text) > 280:\n",
    "            random_text = random_text[0,279]\n",
    "        self.comment_text = random_text\n",
    "\n",
    "class Retweet:\n",
    "    def __init__(self):\n",
    "        self.op_tweet_id = randint(1,100001)\n",
    "        self.retweeter_id = randint(1, 10001)\n",
    "\n",
    "class RetweetedComment:\n",
    "    def __init__(self):\n",
    "        self.comment_id = randint(1, 300001)\n",
    "        self.op_tweet_id = randint(1,100001)\n",
    "        self.retweeter_id = randint(1, 10001)\n",
    "\n",
    "class TweetLike:\n",
    "    def __init__(self):\n",
    "        self.user_id = randint(1,10001)\n",
    "        self.tweet_id = randint(1,100001)\n",
    "\n",
    "class CommentLike:\n",
    "    def __init__(self):\n",
    "        self.comment_id = randint(1,300001)\n",
    "        self.commenter_id = randint(1,10001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the Random Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use nested list comprehensions to generate the fake data. The MySQL syntax for inserting data is INSERT INTO table VALUES (data,data,data); \n",
    "\n",
    "In order to create the data in this format, we first instantiate a list of objects from each class above via the following: \n",
    "[Class() for j in range(number)] \n",
    "\n",
    "We then iterate over this list of objects to retrieve the attributes for each object, organized in tuples, so:\n",
    "our_list = [(attribute1, attribute2) for i in [Class() for j in range(number)]].\n",
    "\n",
    "Please note that this code may take several minutes to run, as it is generating 925,000 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of 10,000 Users for the users table:\n",
    "user_data = [(i.user_handle, i.first_name, i.last_name, i.email_address, i.phone_number, i.birthday) for i in [User() for j in range(10000)]]\n",
    "\n",
    "# Generate a list of unique following interactions for the followers table, to be compliant with the MySQL primary key restrictions.\n",
    "followers_data = set([(i.follower_id, i.following_id) for i in [Follower() for j in range(100000)]])\n",
    "\n",
    "# Generate a list of 100,000 random tweets by random users:\n",
    "tweets = [(i.user_id, i.tweet_text) for i in [Tweet() for j in range(100000)]]\n",
    "\n",
    "# Generate a list of 100,000 random comments by random users:\n",
    "base_comments = [(i.op_tweet_id, i.commenter_id, i.comment_text) for i in [BaseComment() for j in range(100000)]]\n",
    "\n",
    "# Generate a list of 200,000 random subcomments by random users:\n",
    "sub_comments = [(i.parent_comment_id, i.op_tweet_id, i.commenter_id, i.comment_text) for i in [SubComment() for j in range(200000)]]\n",
    "\n",
    "# Generate a list of 10,000 retweets\n",
    "retweets = [(i.op_tweet_id, i.retweeter_id) for i in [Retweet() for j in range(10000)]]\n",
    "\n",
    "# Generate a list of 5,000 retweeted comments (can be retweeted subcomment)\n",
    "retweeted_comments = [(i.op_tweet_id, i.comment_id, i.retweeter_id) for i in [RetweetedComment() for j in range(50000)]]\n",
    "\n",
    "# Generate a set of unique tweet likes to satisfy the MySQL primary key requirements.\n",
    "# Note - This is because a user cannot like a tweet more than once\n",
    "tweet_likes = set([(i.user_id, i.tweet_id) for i in [TweetLike() for j in range(200000)]])\n",
    "\n",
    "# Generate a set of unique comment likes to satisfy the MySQL primary key requirements (includes likes on subcomments)\n",
    "comment_likes = set([(i.comment_id, i.commenter_id) for i in [CommentLike() for j in range(200000)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the hashtag_list and hashtag_instances data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to Python syntax where tuples with only one entry must be written as (entry,) we can't use the same list comprehension methodology as before but instead must use the following for loop to generate the hasthag_list. The hashtag_instances data can be created with the comprehensions like the others, though, because they contain two entries in the tuples. But the hashtag_instances class must be defined following the hashtag_list because its __init__ method depends on the length of hashtag_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hashtag:\n",
    "    def __init__(self):\n",
    "        self.hashtag_name = fake.text().split()[1] # Choose index 1 because the word at index 0 is always capitalized\n",
    "\n",
    "# Generate the list of unique hashtags in hashtag_list\n",
    "hashtag_list = list(set([(j.hashtag_name) for j in [Hashtag() for k in range(4000)]]))\n",
    "\n",
    "# Iterate over the list to create the string query for MySQL\n",
    "query_hashtag_list = \"INSERT INTO hashtag_list (hashtag_name) VALUES \"\n",
    "for x in hashtag_list:\n",
    "    query_hashtag_list += f\"('{x}'), \"\n",
    "    \n",
    "# We need to remove the last comma before placing the ; delimiter \n",
    "query_hashtag_list = query_hashtag_list[:-2] + \"; \\n\\n\" \n",
    "\n",
    "class HashtagInstance:\n",
    "    def __init__(self):\n",
    "        self.hashtag_id = randint(1,len(hashtag_list)+1)\n",
    "        self.tweet_id = randint(1,100001)\n",
    "\n",
    "# Generate a list of 20,000 hashtag instances\n",
    "hashtag_instances = [(i.hashtag_id, i.tweet_id) for i in [HashtagInstance() for j in range(20000)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the MySQL INSERT Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each list we created (except for the hashtag_list, whose query is already written), we now convert each list of tuples into a string and slice it to remove the brackets: str(our_list)[1:-1]. This gives us a string containing only the tupled values we want for the MySQL insert. This is concatenated with the relevant INSERT INTO query syntax. All of the INSERT INTO queries for each table are then concatenated to form one large string, which is then written to a text file for future reference. We are writing the data to text files to store them permanently because this Python script will generate a new list of random data each time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_users = \"INSERT INTO users (user_handle, first_name, last_name, email_address, phone_number, birthday) VALUES \" + str(user_data)[1:-1] + \"; \\n\\n\"\n",
    "query_followers = \"INSERT INTO followers (follower_id, following_id) VALUES \" + str(followers_data)[1:-1] + \"; \\n\"\n",
    "query_tweets = \"INSERT INTO tweets (user_id, tweet_text) VALUES \" + str(tweets)[1:-1] + \"; \\n\\n\"\n",
    "query_base_comments = \"INSERT INTO comments (op_tweet_id, commenter_id, comment_text) VALUES \" + str(base_comments)[1:-1] + \"; \\n\\n\"\n",
    "query_sub_comments = \"INSERT INTO comments (parent_comment_id, op_tweet_id, commenter_id, comment_text) VALUES \" + str(sub_comments)[1:-1] + \"; \\n\\n\"\n",
    "query_retweets = \"INSERT INTO retweets (op_tweet_id, retweeter_id) VALUES \" + str(retweets)[1:-1] + \"; \\n\\n\"\n",
    "query_retweeted_comments = \"INSERT INTO retweets (op_tweet_id, comment_id, retweeter_id) VALUES \" + str(retweeted_comments)[1:-1] + \"; \\n\\n\"\n",
    "query_hashtag_instances = \"INSERT INTO hashtag_instances (hashtag_id, tweet_id) VALUES \" + str(hashtag_instances)[1:-1] + \"; \\n\\n\"\n",
    "query_tweet_likes = \"INSERT INTO tweet_likes (user_id, tweet_id) VALUES \" + str(tweet_likes)[1:-1] + \"; \\n\\n\"\n",
    "query_comment_likes = \"INSERT INTO comment_likes (comment_id, commenter_id) VALUES \" + str(comment_likes)[1:-1] + \"; \\n\\n\"\n",
    "\n",
    "total_query = query_users + query_followers + query_tweets + query_base_comments + query_sub_comments + query_retweets + query_retweeted_comments + query_hashtag_list + query_hashtag_instances + query_tweet_likes + query_comment_likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the MySQL query to a text file for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code will generate separate text files for the data to be inputted into each table, as well as all data compiled into a single file called ALL_DATA.txt. You can then inspect the data for yourself in each individual file. When ready, you can convert them into .sql files and run them directly in MySQL, as long as you start each file with the query USE mock_twitter_db; followed by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"users.txt\",\"w\")\n",
    "file1.write(query_users)\n",
    "file1.close()\n",
    "\n",
    "file2 = open(\"followers.txt\",\"w\")\n",
    "file2.write(query_followers)\n",
    "file2.close()\n",
    "\n",
    "file3 = open(\"tweets.txt\",\"w\")\n",
    "file3.write(query_tweets)\n",
    "file3.close()\n",
    "\n",
    "file4 = open(\"base_comments.txt\",\"w\")\n",
    "file4.write(query_base_comments)\n",
    "file4.close()\n",
    "\n",
    "file5 = open(\"sub_comments.txt\",\"w\")\n",
    "file5.write(query_sub_comments)\n",
    "file5.close()\n",
    "\n",
    "file6 = open(\"retweets.txt\",\"w\")\n",
    "file6.write(query_retweets)\n",
    "file6.close()\n",
    "\n",
    "file7 = open(\"retweeted_comments.txt\",\"w\")\n",
    "file7.write(query_retweeted_comments)\n",
    "file7.close()\n",
    "\n",
    "file8 = open(\"hashtag_list.txt\",\"w\")\n",
    "file8.write(query_hashtag_list)\n",
    "file8.close()\n",
    "\n",
    "file9 = open(\"hashstag_instances.txt\",\"w\")\n",
    "file9.write(query_hashtag_instances)\n",
    "file9.close()\n",
    "\n",
    "file10 = open(\"tweet_likes.txt\",\"w\")\n",
    "file10.write(query_tweet_likes)\n",
    "file10.close()\n",
    "\n",
    "file11 = open(\"comment_likes.txt\",\"w\")\n",
    "file11.write(query_comment_likes)\n",
    "file11.close()\n",
    "\n",
    "total_query_file = open(\"ALL_DATA.txt\",\"w\")\n",
    "total_query_file.write(total_query)\n",
    "total_query_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
